{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0t3zYINlQvci5as/gAYAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya29J/CodeHer_25-InSpec-AI/blob/main/Vehicle_Defect_Detection_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Mounting Drive***"
      ],
      "metadata": {
        "id": "FiSshywFONoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q7bCM4o0y98h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "920b4a48-08f4-4dda-af07-c8607934d63d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "***Unzip Dataset File***"
      ],
      "metadata": {
        "id": "Yh3kyf7WOWBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/archive (1).zip'\n",
        "extract_path = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/'\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Print the contents of the extracted folder\n",
        "print(\"Contents of extracted folder:\", os.listdir(extract_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "44icS9QvzRsD",
        "outputId": "8c8af07e-0606-440b-8836-9f27a378ee00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of extracted folder: ['archive (1).zip', 'car_parts_prices.json', 'archive (2).zip', 'annotation LABELME', 'data3a', 'yolo_labels']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Model Definition (MNV2)***"
      ],
      "metadata": {
        "id": "u4xlEf3uJQgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# === 1. Set Paths ===\n",
        "train_dir = \"/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/data3a/training\"\n",
        "val_dir = \"/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/data3a/validation\"\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# === 2. Data Augmentation ===\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2]\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# === 3. Compute Class Weights ===\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# === 4. Load Pretrained MobileNetV2 Base ===\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # Freeze base model initially\n",
        "\n",
        "# === 5. Add Custom Layers ===\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)                     # Increased dropout\n",
        "x = Dense(128, activation='relu')(x)    # New layer\n",
        "x = Dropout(0.3)(x)                     # New dropout\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# === 6. Compile Model ===\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# === 7. Callbacks ===\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor='val_accuracy'),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2)\n",
        "]\n",
        "\n",
        "# === 8. Train Top Layers ===\n",
        "initial_epochs = 15\n",
        "\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "validation_steps = val_generator.samples // batch_size\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=initial_epochs,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# === 9. Fine-Tune Base Model ===\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False  # Freeze first 100 layers\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fine_tune_epochs = 10\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=fine_tune_epochs,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# === 10. Final Evaluation and Save ===\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Save with accuracy in filename\n",
        "model.save(f\"fine_tuned_vehicle_model_acc_{accuracy*100:.2f}.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ThjLYd2WIn4j",
        "outputId": "4211d49f-ea76-4ce9-cd60-0928d3e1e41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1383 images belonging to 3 classes.\n",
            "Found 248 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 7s/step - accuracy: 0.3494 - loss: 1.3563 - val_accuracy: 0.5759 - val_loss: 0.9723 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m 1/43\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 1s/step - accuracy: 0.2812 - loss: 1.2677"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 310ms/step - accuracy: 0.2812 - loss: 1.2677 - val_accuracy: 0.5580 - val_loss: 0.9707 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.4126 - loss: 1.1194 - val_accuracy: 0.6205 - val_loss: 0.8975 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 441ms/step - accuracy: 0.3750 - loss: 1.2400 - val_accuracy: 0.5938 - val_loss: 0.9036 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.4798 - loss: 1.0431 - val_accuracy: 0.6295 - val_loss: 0.8758 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 290ms/step - accuracy: 0.4062 - loss: 1.1241 - val_accuracy: 0.6518 - val_loss: 0.8634 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5071 - loss: 1.0047 - val_accuracy: 0.6741 - val_loss: 0.8434 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 421ms/step - accuracy: 0.4375 - loss: 1.1548 - val_accuracy: 0.6830 - val_loss: 0.8339 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5315 - loss: 0.9448 - val_accuracy: 0.6518 - val_loss: 0.8170 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 460ms/step - accuracy: 0.4688 - loss: 1.1328 - val_accuracy: 0.6741 - val_loss: 0.8163 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 2s/step - accuracy: 0.5607 - loss: 0.9123 - val_accuracy: 0.6741 - val_loss: 0.8202 - learning_rate: 5.0000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 458ms/step - accuracy: 0.5625 - loss: 0.9665 - val_accuracy: 0.6830 - val_loss: 0.8012 - learning_rate: 5.0000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5349 - loss: 0.9400 - val_accuracy: 0.6696 - val_loss: 0.7878 - learning_rate: 2.5000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 451ms/step - accuracy: 0.5000 - loss: 1.0020 - val_accuracy: 0.6652 - val_loss: 0.7939 - learning_rate: 2.5000e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.5270 - loss: 0.9557 - val_accuracy: 0.6786 - val_loss: 0.7827 - learning_rate: 1.2500e-05\n",
            "Epoch 1/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3s/step - accuracy: 0.4504 - loss: 1.0497 - val_accuracy: 0.6741 - val_loss: 0.7809 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 270ms/step - accuracy: 0.4688 - loss: 1.1209 - val_accuracy: 0.6741 - val_loss: 0.7765 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - accuracy: 0.4887 - loss: 1.0383 - val_accuracy: 0.7009 - val_loss: 0.7479 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 228ms/step - accuracy: 0.5000 - loss: 0.9782 - val_accuracy: 0.6920 - val_loss: 0.7615 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 5s/step - accuracy: 0.5073 - loss: 0.9986 - val_accuracy: 0.6875 - val_loss: 0.7468 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 405ms/step - accuracy: 0.6875 - loss: 0.8349 - val_accuracy: 0.6964 - val_loss: 0.7453 - learning_rate: 5.0000e-06\n",
            "Epoch 7/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5048 - loss: 0.9600 - val_accuracy: 0.6875 - val_loss: 0.7491 - learning_rate: 5.0000e-06\n",
            "Epoch 8/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 437ms/step - accuracy: 0.4688 - loss: 1.1307 - val_accuracy: 0.6830 - val_loss: 0.7508 - learning_rate: 2.5000e-06\n",
            "Epoch 9/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 3s/step - accuracy: 0.5261 - loss: 0.9323 - val_accuracy: 0.7009 - val_loss: 0.7461 - learning_rate: 2.5000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6850 - loss: 0.7575\n",
            "Validation Accuracy: 68.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluate and Save***"
      ],
      "metadata": {
        "id": "6hZ6HrLFOGLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Create folder path\n",
        "save_path = \"/content/drive/My Drive/Vehicle_Defect_Detection/models/\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "model.save(save_path + \"vehicle_damage_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iJLa0gjr6QA5",
        "outputId": "4f862004-cb98-4f85-d396-dac3bf206c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6987 - loss: 0.7367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 68.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load Model***"
      ],
      "metadata": {
        "id": "n_N909HANpPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load previously trained model\n",
        "model = load_model(\"vehicle_damage_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxmRdkhWe9Cr",
        "outputId": "85f6a050-9050-40ea-fa85-4cd343002cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Image Augmentation + Normalization***"
      ],
      "metadata": {
        "id": "d8J1tknmJA9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_dir = \"/content/vehicle_data/data3a/training\"\n",
        "val_dir = \"/content/vehicle_data/data3a/validation\"\n",
        "\n",
        "# Image augmentation and normalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load images again to refresh class count\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gLqarTbG2llJ",
        "outputId": "2f2bd690-d1b0-4c58-eaf0-14c520976d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1383 images belonging to 3 classes.\n",
            "Found 248 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Car Parts Price File Load***"
      ],
      "metadata": {
        "id": "gchjGD7g6EwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define path\n",
        "json_file_path = \"/content/drive/My Drive/Vehicle_Defect_Detection/Vehicle_Dataset/car_parts_prices.json\"\n",
        "\n",
        "# Load JSON data\n",
        "with open(json_file_path, 'r') as file:\n",
        "    car_parts_prices = json.load(file)\n",
        "\n",
        "# View a sample\n",
        "print(list(car_parts_prices.items())[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8LEQh2a6CvR",
        "outputId": "b0de43a0-a464-4a4a-af17-e4f8a0bd474c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('HONDA', {'City': {'Bonnet': 15000, 'Bumper': 10000, 'Dickey': 8000, 'Door': 20000, 'Fender': 5000, 'Light': 3000, 'Windshield': 8000}, 'Amaze': {'Bonnet': 12000, 'Bumper': 8000, 'Dickey': 6000, 'Door': 18000, 'Fender': 4000, 'Light': 2500, 'Windshield': 7000}, 'WR-V': {'Bonnet': 16000, 'Bumper': 11000, 'Dickey': 9000, 'Door': 22000, 'Fender': 6000, 'Light': 3500, 'Windshield': 9000}, 'Jazz': {'Bonnet': 14000, 'Bumper': 9000, 'Dickey': 7000, 'Door': 19000, 'Fender': 4500, 'Light': 2800, 'Windshield': 8000}, 'HR-V': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}, 'Pilot': {'Bonnet': 22000, 'Bumper': 15000, 'Dickey': 13000, 'Door': 28000, 'Fender': 8000, 'Light': 5000, 'Windshield': 12000}, 'CR-V': {'Bonnet': 20000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}, 'Accord': {'Bonnet': 22000, 'Bumper': 15000, 'Dickey': 13000, 'Door': 28000, 'Fender': 8000, 'Light': 5000, 'Windshield': 12000}, 'Civic': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}}), ('MARUTI SUZUKI', {'Swift': {'Bonnet': 10000, 'Bumper': 7000, 'Dickey': 5000, 'Door': 15000, 'Fender': 3000, 'Light': 2000, 'Windshield': 6000}, 'Baleno': {'Bonnet': 12000, 'Bumper': 8000, 'Dickey': 6000, 'Door': 18000, 'Fender': 4000, 'Light': 2500, 'Windshield': 7000}, 'Vitara Brezza': {'Bonnet': 14000, 'Bumper': 9000, 'Dickey': 7000, 'Door': 20000, 'Fender': 4500, 'Light': 2800, 'Windshield': 8000}, 'Wagon R': {'Bonnet': 12000, 'Bumper': 8000, 'Dickey': 6000, 'Door': 18000, 'Fender': 4000, 'Light': 2500, 'Windshield': 7000}, 'Ertiga': {'Bonnet': 16000, 'Bumper': 11000, 'Dickey': 9000, 'Door': 22000, 'Fender': 6000, 'Light': 3500, 'Windshield': 9000}, 'Grand Vitara': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}}), ('TOYOTA', {'Corolla': {'Bonnet': 20000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}, 'Camry': {'Bonnet': 22000, 'Bumper': 15000, 'Dickey': 13000, 'Door': 28000, 'Fender': 8000, 'Light': 5000, 'Windshield': 12000}, 'Fortuner': {'Bonnet': 25000, 'Bumper': 17000, 'Dickey': 15000, 'Door': 30000, 'Fender': 9000, 'Light': 6000, 'Windshield': 14000}, 'Innova': {'Bonnet': 23000, 'Bumper': 16000, 'Dickey': 14000, 'Door': 29000, 'Fender': 8500, 'Light': 5500, 'Windshield': 13000}, 'Yaris': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}}), ('HYUNDAI', {'i20': {'Bonnet': 15000, 'Bumper': 10000, 'Dickey': 8000, 'Door': 20000, 'Fender': 5000, 'Light': 3000, 'Windshield': 8000}, 'Creta': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}, 'Verna': {'Bonnet': 16000, 'Bumper': 11000, 'Dickey': 9000, 'Door': 22000, 'Fender': 6000, 'Light': 3500, 'Windshield': 9000}, 'Venue': {'Bonnet': 17000, 'Bumper': 11500, 'Dickey': 9500, 'Door': 23000, 'Fender': 6500, 'Light': 3750, 'Windshield': 9500}, 'Tucson': {'Bonnet': 20000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}}), ('NISSAN', {'Altima': {'Bonnet': 18000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}, 'Rogue': {'Bonnet': 20000, 'Bumper': 14000, 'Dickey': 12000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}, 'Sentra': {'Bonnet': 17000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 22000, 'Fender': 6500, 'Light': 3750, 'Windshield': 9500}, 'Pathfinder': {'Bonnet': 18000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}, 'Titan': {'Bonnet': 20000, 'Bumper': 14000, 'Dickey': 12000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Price Estimate Prediction***"
      ],
      "metadata": {
        "id": "EoYcB8oyB-Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the trained MobileNetV2 model\n",
        "model_path = '/content/drive/MyDrive/Vehicle_Defect_Detection/models/vehicle_damage_model.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Load the price data\n",
        "price_file_path = '/content/drive/My Drive/Vehicle_Defect_Detection/Vehicle_Dataset/car_parts_prices.json'\n",
        "with open(price_file_path, 'r') as f:\n",
        "    price_data = json.load(f)\n",
        "\n",
        "# Define class labels used in training\n",
        "class_labels = ['minor', 'moderate', 'severe']\n",
        "\n",
        "# Define severity multipliers\n",
        "severity_multiplier = {\n",
        "    'minor': 0.5,\n",
        "    'moderate': 1.0,\n",
        "    'severe': 1.5}\n",
        "\n",
        "# Function to predict severity\n",
        "def predict_severity(image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    severity_index = np.argmax(predictions)\n",
        "    severity_label = class_labels[severity_index]\n",
        "\n",
        "    return severity_label\n",
        "\n",
        "\n",
        "# Function to estimate repair cost\n",
        "def estimate_repair_cost(brand, model_name, part, severity):\n",
        "    brand = brand.upper().strip()\n",
        "    model_name = model_name.strip()\n",
        "    part_input = part.strip().lower()\n",
        "    severity = severity.lower().strip()\n",
        "\n",
        "    try:\n",
        "\n",
        "        available_parts = price_data[brand][model_name]\n",
        "        matched_part = None\n",
        "        for actual_part in available_parts.keys():\n",
        "            if actual_part.strip().lower() == part_input:\n",
        "                matched_part = actual_part\n",
        "                break\n",
        "\n",
        "        if not matched_part:\n",
        "            return f\"Unknown: part '{part}' not found\"\n",
        "\n",
        "        base_price = price_data[brand][model_name][matched_part]\n",
        "        multiplier = severity_multiplier.get(severity, 1.0)\n",
        "        estimated_cost = int(base_price * multiplier)\n",
        "        return f\"₹{estimated_cost}\"\n",
        "    except KeyError as e:\n",
        "        return f\"Unknown: {e.args[0]} not found\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAVsHucC6oVf",
        "outputId": "9dc50bfd-ce5d-4c73-db8f-cbacf1ecccad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    }
  ]
}