{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXW653tPoO2lMd59eas+2S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya29J/CodeHer_25-InSpec-AI/blob/main/Vehicle_Defect_Detection_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Mounting Drive***"
      ],
      "metadata": {
        "id": "FiSshywFONoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Q7bCM4o0y98h",
        "outputId": "b67a6b6b-c425-4029-8bcd-ebb33c4547ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset'\n",
        "print(\"Contents of dataset folder:\", os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BDtP9Ux4zCne",
        "outputId": "f8b1a224-6069-420d-9327-c892cdbe6886"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of dataset folder: ['archive (1).zip', 'car_parts_prices.json', 'archive (2).zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Unzip Dataset(T) File***"
      ],
      "metadata": {
        "id": "azNfIoI1Dkho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/archive (2).zip'\n",
        "extract_path = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"archive (2).zip extracted successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM1ngjOfDj8y",
        "outputId": "006b5fc9-8293-4288-a56d-315d164210ac"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "archive (2).zip extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Converting Labelme to YOLO***"
      ],
      "metadata": {
        "id": "9Xe62-s6KctE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Function to convert LabelMe annotations to YOLO format\n",
        "def convert_labelme_to_yolo(annotation_file, image_width, image_height):\n",
        "    with open(annotation_file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    yolo_annotations = []\n",
        "\n",
        "    for shape in data['shapes']:\n",
        "        label = shape['label']  # Get the label\n",
        "        points = shape['points']  # Get the points of the polygon\n",
        "        # Convert points to a bounding box (x_min, y_min, x_max, y_max)\n",
        "        x_min = min([point[0] for point in points])\n",
        "        y_min = min([point[1] for point in points])\n",
        "        x_max = max([point[0] for point in points])\n",
        "        y_max = max([point[1] for point in points])\n",
        "\n",
        "        # Normalize the coordinates to be between 0 and 1\n",
        "        center_x = (x_min + x_max) / 2 / image_width\n",
        "        center_y = (y_min + y_max) / 2 / image_height\n",
        "        width = (x_max - x_min) / image_width\n",
        "        height = (y_max - y_min) / image_height\n",
        "\n",
        "\n",
        "        class_id = 0\n",
        "\n",
        "        # Add the annotation to the list\n",
        "        yolo_annotations.append(f\"{class_id} {center_x} {center_y} {width} {height}\")\n",
        "\n",
        "    return yolo_annotations\n",
        "\n",
        "# Example for processing all annotations\n",
        "annotations_path = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/annotation LABELME'\n",
        "image_folder = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/images'\n",
        "\n",
        "# Output folder for YOLO annotations\n",
        "output_folder = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/yolo_labels'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Loop through JSON annotation files and convert them\n",
        "for annotation_file in os.listdir(annotations_path):\n",
        "    if annotation_file.endswith('.json'):\n",
        "        json_path = os.path.join(annotations_path, annotation_file)\n",
        "\n",
        "\n",
        "        image_width, image_height = 800, 600\n",
        "\n",
        "        # Convert the annotations\n",
        "        yolo_annotations = convert_labelme_to_yolo(json_path, image_width, image_height)\n",
        "\n",
        "        # Save to a text file in the YOLO format\n",
        "        image_name = os.path.splitext(annotation_file)[0] + '.txt'  # Match with image name\n",
        "        yolo_file_path = os.path.join(output_folder, image_name)\n",
        "\n",
        "        with open(yolo_file_path, 'w') as f:\n",
        "            f.write(\"\\n\".join(yolo_annotations))\n",
        "\n",
        "        print(f\"Converted {annotation_file} to YOLO format.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5K1zo4xwKwi2",
        "outputId": "3183f75a-88f4-4e65-bae6-6fd0e14d51b4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 1.json to YOLO format.\n",
            "Converted 10.json to YOLO format.\n",
            "Converted 14.json to YOLO format.\n",
            "Converted 15.json to YOLO format.\n",
            "Converted 16.json to YOLO format.\n",
            "Converted 17.json to YOLO format.\n",
            "Converted 18.json to YOLO format.\n",
            "Converted 19.json to YOLO format.\n",
            "Converted 2.json to YOLO format.\n",
            "Converted 20.json to YOLO format.\n",
            "Converted 21.json to YOLO format.\n",
            "Converted 22.json to YOLO format.\n",
            "Converted 23.json to YOLO format.\n",
            "Converted 24.json to YOLO format.\n",
            "Converted 25.json to YOLO format.\n",
            "Converted 26.json to YOLO format.\n",
            "Converted 27.json to YOLO format.\n",
            "Converted 29.json to YOLO format.\n",
            "Converted 3.json to YOLO format.\n",
            "Converted 30.json to YOLO format.\n",
            "Converted 31.json to YOLO format.\n",
            "Converted 32.json to YOLO format.\n",
            "Converted 33.json to YOLO format.\n",
            "Converted 34.json to YOLO format.\n",
            "Converted 36.json to YOLO format.\n",
            "Converted 37.json to YOLO format.\n",
            "Converted 38.json to YOLO format.\n",
            "Converted 39.json to YOLO format.\n",
            "Converted 4.json to YOLO format.\n",
            "Converted 40.json to YOLO format.\n",
            "Converted 41.json to YOLO format.\n",
            "Converted 42.json to YOLO format.\n",
            "Converted 43.json to YOLO format.\n",
            "Converted 44.json to YOLO format.\n",
            "Converted 46.json to YOLO format.\n",
            "Converted 5.json to YOLO format.\n",
            "Converted 51.json to YOLO format.\n",
            "Converted 52.json to YOLO format.\n",
            "Converted 53.json to YOLO format.\n",
            "Converted 54.json to YOLO format.\n",
            "Converted 55.json to YOLO format.\n",
            "Converted 56.json to YOLO format.\n",
            "Converted 57.json to YOLO format.\n",
            "Converted 58.json to YOLO format.\n",
            "Converted 59.json to YOLO format.\n",
            "Converted 6.json to YOLO format.\n",
            "Converted 61.json to YOLO format.\n",
            "Converted 62.json to YOLO format.\n",
            "Converted 63.json to YOLO format.\n",
            "Converted 64.json to YOLO format.\n",
            "Converted 68.json to YOLO format.\n",
            "Converted 69.json to YOLO format.\n",
            "Converted 7.json to YOLO format.\n",
            "Converted 70.json to YOLO format.\n",
            "Converted 71.json to YOLO format.\n",
            "Converted 73.json to YOLO format.\n",
            "Converted 74.json to YOLO format.\n",
            "Converted 77.json to YOLO format.\n",
            "Converted 78.json to YOLO format.\n",
            "Converted 79.json to YOLO format.\n",
            "Converted 8.json to YOLO format.\n",
            "Converted 80.json to YOLO format.\n",
            "Converted 9.json to YOLO format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Define class names based on the unique labels\n",
        "class_names = [\n",
        "    'broken - front headlight',\n",
        "    'broken - windshield',\n",
        "    'dent - door',\n",
        "    'dent - front bumper',\n",
        "    'dent - rear bumper',\n",
        "    'scratch - door',\n",
        "    'scratch - front bumper',\n",
        "    'scratch - rear bumper'\n",
        "]\n",
        "\n",
        "# Create the dataset.yaml file\n",
        "data = {\n",
        "    'train': '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/images/train',\n",
        "    'val': '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/images/val',\n",
        "    'nc': len(class_names),\n",
        "    'names': class_names\n",
        "}\n",
        "\n",
        "yaml_file_path = '/content/drive/MyDrive/custom_dataset.yaml'\n",
        "with open(yaml_file_path, 'w') as outfile:\n",
        "    yaml.dump(data, outfile, default_flow_style=False)\n",
        "\n",
        "print(f\"custom_dataset.yaml created at {yaml_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofp23-xE9gHq",
        "outputId": "4a2dc6d6-9a54-49df-ebb5-ecb8ca807b05"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom_dataset.yaml created at /content/drive/MyDrive/custom_dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "\n",
        "# Change directory to yolov5 folder\n",
        "%cd yolov5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj09wQ219ycl",
        "outputId": "2738f47d-c052-4205-bbda-ed5df884989d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17360, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 17360 (delta 36), reused 18 (delta 18), pack-reused 17308 (from 2)\u001b[K\n",
            "Receiving objects: 100% (17360/17360), 16.25 MiB | 24.01 MiB/s, done.\n",
            "Resolving deltas: 100% (11901/11901), done.\n",
            "/content/yolov5/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5\n",
        "!python train.py --img 640 --batch 16 --epochs 10 --data /content/drive/MyDrive/custom_dataset.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv6eGRCdGzVP",
        "outputId": "d7895acd-f6b9-457d-ee06-f506c908793b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "2025-04-05 18:04:14.081609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743876254.125052   33543 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743876254.138125   33543 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/drive/MyDrive/custom_dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-411-gf4d8a84c Python-3.11.11 torch-2.6.0+cu124 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     29667  models.yolo.Detect                      [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7035811 parameters, 7035811 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...'mask_interpolation': 0}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/data3a/train/01-minor... 0 images, 1383 backgrounds, 0 corrupt: 100% 1383/1383 [00:13<00:00, 102.81it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ No labels found in /content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/data3a/train/01-minor.cache. See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/data3a/train/01-minor.cache\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 986, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 688, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 285, in train\n",
            "    train_loader, dataset = create_dataloader(\n",
            "                            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 184, in create_dataloader\n",
            "    dataset = LoadImagesAndLabels(\n",
            "              ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 611, in __init__\n",
            "    assert nf > 0 or not augment, f\"{prefix}No labels found in {cache_path}, can not start training. {HELP_URL}\"\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in /content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/data3a/train/01-minor.cache, can not start training. See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U setuptools wheel\n",
        "!pip install -U pip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jPHh_k3RLvzZ",
        "outputId": "f1a46ee1-cae2-431e-e89c-865fe1f1a9cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~ip (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (78.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~ip (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ip (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ip (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.0.1)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~ip (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ip (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall ultralytics -y\n",
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V4iB5jeQ_I85",
        "outputId": "1443539a-b6bc-4d6b-ce34-58bfc2d60f69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: ultralytics 8.3.102\n",
            "Uninstalling ultralytics-8.3.102:\n",
            "  Successfully uninstalled ultralytics-8.3.102\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~ip (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting ultralytics\n",
            "  Using cached ultralytics-8.3.102-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Using cached ultralytics-8.3.102-py3-none-any.whl (993 kB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~ip (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: ultralytics\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~ip (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed ultralytics-8.3.102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "print(ultralytics.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_jiSjF4BFGW",
        "outputId": "0808b821-cab7-433e-9f31-a23aba79bdaa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.3.102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Unzip Dataset(S) File***"
      ],
      "metadata": {
        "id": "Yh3kyf7WOWBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/archive (1).zip'\n",
        "extract_path = '/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/'\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Print the contents of the extracted folder\n",
        "print(\"Contents of extracted folder:\", os.listdir(extract_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "44icS9QvzRsD",
        "outputId": "8c8af07e-0606-440b-8836-9f27a378ee00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of extracted folder: ['archive (1).zip', 'car_parts_prices.json', 'archive (2).zip', 'annotation LABELME', 'data3a', 'yolo_labels']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Model Definition (MNV2)***"
      ],
      "metadata": {
        "id": "u4xlEf3uJQgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# === 1. Set Paths ===\n",
        "train_dir = \"/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/data3a/training\"\n",
        "val_dir = \"/content/drive/MyDrive/Vehicle_Defect_Detection (1)/Vehicle_Dataset/data3a/validation\"\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# === 2. Data Augmentation ===\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2]\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# === 3. Compute Class Weights ===\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# === 4. Load Pretrained MobileNetV2 Base ===\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # Freeze base model initially\n",
        "\n",
        "# === 5. Add Custom Layers ===\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)                     # Increased dropout\n",
        "x = Dense(128, activation='relu')(x)    # New layer\n",
        "x = Dropout(0.3)(x)                     # New dropout\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# === 6. Compile Model ===\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# === 7. Callbacks ===\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor='val_accuracy'),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2)\n",
        "]\n",
        "\n",
        "# === 8. Train Top Layers ===\n",
        "initial_epochs = 15\n",
        "\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "validation_steps = val_generator.samples // batch_size\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=initial_epochs,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# === 9. Fine-Tune Base Model ===\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False  # Freeze first 100 layers\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fine_tune_epochs = 10\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=fine_tune_epochs,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# === 10. Final Evaluation and Save ===\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Save with accuracy in filename\n",
        "model.save(f\"fine_tuned_vehicle_model_acc_{accuracy*100:.2f}.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ThjLYd2WIn4j",
        "outputId": "4211d49f-ea76-4ce9-cd60-0928d3e1e41e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1383 images belonging to 3 classes.\n",
            "Found 248 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 7s/step - accuracy: 0.3494 - loss: 1.3563 - val_accuracy: 0.5759 - val_loss: 0.9723 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m 1/43\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 1s/step - accuracy: 0.2812 - loss: 1.2677"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 310ms/step - accuracy: 0.2812 - loss: 1.2677 - val_accuracy: 0.5580 - val_loss: 0.9707 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.4126 - loss: 1.1194 - val_accuracy: 0.6205 - val_loss: 0.8975 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 441ms/step - accuracy: 0.3750 - loss: 1.2400 - val_accuracy: 0.5938 - val_loss: 0.9036 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.4798 - loss: 1.0431 - val_accuracy: 0.6295 - val_loss: 0.8758 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 290ms/step - accuracy: 0.4062 - loss: 1.1241 - val_accuracy: 0.6518 - val_loss: 0.8634 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5071 - loss: 1.0047 - val_accuracy: 0.6741 - val_loss: 0.8434 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 421ms/step - accuracy: 0.4375 - loss: 1.1548 - val_accuracy: 0.6830 - val_loss: 0.8339 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5315 - loss: 0.9448 - val_accuracy: 0.6518 - val_loss: 0.8170 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 460ms/step - accuracy: 0.4688 - loss: 1.1328 - val_accuracy: 0.6741 - val_loss: 0.8163 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 2s/step - accuracy: 0.5607 - loss: 0.9123 - val_accuracy: 0.6741 - val_loss: 0.8202 - learning_rate: 5.0000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 458ms/step - accuracy: 0.5625 - loss: 0.9665 - val_accuracy: 0.6830 - val_loss: 0.8012 - learning_rate: 5.0000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5349 - loss: 0.9400 - val_accuracy: 0.6696 - val_loss: 0.7878 - learning_rate: 2.5000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 451ms/step - accuracy: 0.5000 - loss: 1.0020 - val_accuracy: 0.6652 - val_loss: 0.7939 - learning_rate: 2.5000e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.5270 - loss: 0.9557 - val_accuracy: 0.6786 - val_loss: 0.7827 - learning_rate: 1.2500e-05\n",
            "Epoch 1/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3s/step - accuracy: 0.4504 - loss: 1.0497 - val_accuracy: 0.6741 - val_loss: 0.7809 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 270ms/step - accuracy: 0.4688 - loss: 1.1209 - val_accuracy: 0.6741 - val_loss: 0.7765 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - accuracy: 0.4887 - loss: 1.0383 - val_accuracy: 0.7009 - val_loss: 0.7479 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 228ms/step - accuracy: 0.5000 - loss: 0.9782 - val_accuracy: 0.6920 - val_loss: 0.7615 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 5s/step - accuracy: 0.5073 - loss: 0.9986 - val_accuracy: 0.6875 - val_loss: 0.7468 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 405ms/step - accuracy: 0.6875 - loss: 0.8349 - val_accuracy: 0.6964 - val_loss: 0.7453 - learning_rate: 5.0000e-06\n",
            "Epoch 7/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5048 - loss: 0.9600 - val_accuracy: 0.6875 - val_loss: 0.7491 - learning_rate: 5.0000e-06\n",
            "Epoch 8/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 437ms/step - accuracy: 0.4688 - loss: 1.1307 - val_accuracy: 0.6830 - val_loss: 0.7508 - learning_rate: 2.5000e-06\n",
            "Epoch 9/10\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 3s/step - accuracy: 0.5261 - loss: 0.9323 - val_accuracy: 0.7009 - val_loss: 0.7461 - learning_rate: 2.5000e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6850 - loss: 0.7575\n",
            "Validation Accuracy: 68.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluate and Save***"
      ],
      "metadata": {
        "id": "6hZ6HrLFOGLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Create folder path\n",
        "save_path = \"/content/drive/My Drive/Vehicle_Defect_Detection/models/\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "model.save(save_path + \"vehicle_damage_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iJLa0gjr6QA5",
        "outputId": "4f862004-cb98-4f85-d396-dac3bf206c3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6987 - loss: 0.7367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 68.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load Model***"
      ],
      "metadata": {
        "id": "n_N909HANpPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load previously trained model\n",
        "model = load_model(\"vehicle_damage_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxmRdkhWe9Cr",
        "outputId": "85f6a050-9050-40ea-fa85-4cd343002cd9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Image Augmentation + Normalization***"
      ],
      "metadata": {
        "id": "d8J1tknmJA9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Correct dataset paths\n",
        "train_dir = \"/content/vehicle_data/data3a/training\"\n",
        "val_dir = \"/content/vehicle_data/data3a/validation\"\n",
        "\n",
        "# Image augmentation and normalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load images again to refresh class count\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gLqarTbG2llJ",
        "outputId": "2f2bd690-d1b0-4c58-eaf0-14c520976d9a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1383 images belonging to 3 classes.\n",
            "Found 248 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Mounting Test Images***"
      ],
      "metadata": {
        "id": "YONMmTagTxc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to test images\n",
        "test_images_dir = '/content/drive/My Drive/Colab_Test_Images'\n",
        "\n",
        "# List all files in the test images directory\n",
        "test_images = os.listdir(test_images_dir)\n",
        "\n",
        "# Display the list of test images\n",
        "print(test_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyL2lZcsRJ5d",
        "outputId": "5c9c28bd-01b4-4292-a2d2-c5a2ec0cdd51"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Severe.jpg', 'Moderate.jpeg', 'Minor.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Car Parts Price File Load***"
      ],
      "metadata": {
        "id": "gchjGD7g6EwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define path\n",
        "json_file_path = \"/content/drive/My Drive/Vehicle Dataset/car_parts_prices.json\"\n",
        "\n",
        "# Load JSON data\n",
        "with open(json_file_path, 'r') as file:\n",
        "    car_parts_prices = json.load(file)\n",
        "\n",
        "# View a sample\n",
        "print(list(car_parts_prices.items())[:5])  # See first 5 entries\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8LEQh2a6CvR",
        "outputId": "9fb6fc0a-19e7-4997-dff0-d0754feaf269"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('HONDA', {'City': {'Bonnet': 15000, 'Bumper': 10000, 'Dickey': 8000, 'Door': 20000, 'Fender': 5000, 'Light': 3000, 'Windshield': 8000}, 'Amaze': {'Bonnet': 12000, 'Bumper': 8000, 'Dickey': 6000, 'Door': 18000, 'Fender': 4000, 'Light': 2500, 'Windshield': 7000}, 'WR-V': {'Bonnet': 16000, 'Bumper': 11000, 'Dickey': 9000, 'Door': 22000, 'Fender': 6000, 'Light': 3500, 'Windshield': 9000}, 'Jazz': {'Bonnet': 14000, 'Bumper': 9000, 'Dickey': 7000, 'Door': 19000, 'Fender': 4500, 'Light': 2800, 'Windshield': 8000}, 'HR-V': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}, 'Pilot': {'Bonnet': 22000, 'Bumper': 15000, 'Dickey': 13000, 'Door': 28000, 'Fender': 8000, 'Light': 5000, 'Windshield': 12000}, 'CR-V': {'Bonnet': 20000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}, 'Accord': {'Bonnet': 22000, 'Bumper': 15000, 'Dickey': 13000, 'Door': 28000, 'Fender': 8000, 'Light': 5000, 'Windshield': 12000}, 'Civic': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}}), ('MARUTI SUZUKI', {'Swift': {'Bonnet': 10000, 'Bumper': 7000, 'Dickey': 5000, 'Door': 15000, 'Fender': 3000, 'Light': 2000, 'Windshield': 6000}, 'Baleno': {'Bonnet': 12000, 'Bumper': 8000, 'Dickey': 6000, 'Door': 18000, 'Fender': 4000, 'Light': 2500, 'Windshield': 7000}, 'Vitara Brezza': {'Bonnet': 14000, 'Bumper': 9000, 'Dickey': 7000, 'Door': 20000, 'Fender': 4500, 'Light': 2800, 'Windshield': 8000}, 'Wagon R': {'Bonnet': 12000, 'Bumper': 8000, 'Dickey': 6000, 'Door': 18000, 'Fender': 4000, 'Light': 2500, 'Windshield': 7000}, 'Ertiga': {'Bonnet': 16000, 'Bumper': 11000, 'Dickey': 9000, 'Door': 22000, 'Fender': 6000, 'Light': 3500, 'Windshield': 9000}, 'Grand Vitara': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}}), ('TOYOTA', {'Corolla': {'Bonnet': 20000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}, 'Camry': {'Bonnet': 22000, 'Bumper': 15000, 'Dickey': 13000, 'Door': 28000, 'Fender': 8000, 'Light': 5000, 'Windshield': 12000}, 'Fortuner': {'Bonnet': 25000, 'Bumper': 17000, 'Dickey': 15000, 'Door': 30000, 'Fender': 9000, 'Light': 6000, 'Windshield': 14000}, 'Innova': {'Bonnet': 23000, 'Bumper': 16000, 'Dickey': 14000, 'Door': 29000, 'Fender': 8500, 'Light': 5500, 'Windshield': 13000}, 'Yaris': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}}), ('HYUNDAI', {'i20': {'Bonnet': 15000, 'Bumper': 10000, 'Dickey': 8000, 'Door': 20000, 'Fender': 5000, 'Light': 3000, 'Windshield': 8000}, 'Creta': {'Bonnet': 18000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}, 'Verna': {'Bonnet': 16000, 'Bumper': 11000, 'Dickey': 9000, 'Door': 22000, 'Fender': 6000, 'Light': 3500, 'Windshield': 9000}, 'Venue': {'Bonnet': 17000, 'Bumper': 11500, 'Dickey': 9500, 'Door': 23000, 'Fender': 6500, 'Light': 3750, 'Windshield': 9500}, 'Tucson': {'Bonnet': 20000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}}), ('NISSAN', {'Altima': {'Bonnet': 18000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}, 'Rogue': {'Bonnet': 20000, 'Bumper': 14000, 'Dickey': 12000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}, 'Sentra': {'Bonnet': 17000, 'Bumper': 12000, 'Dickey': 10000, 'Door': 22000, 'Fender': 6500, 'Light': 3750, 'Windshield': 9500}, 'Pathfinder': {'Bonnet': 18000, 'Bumper': 13000, 'Dickey': 11000, 'Door': 24000, 'Fender': 7000, 'Light': 4000, 'Windshield': 10000}, 'Titan': {'Bonnet': 20000, 'Bumper': 14000, 'Dickey': 12000, 'Door': 26000, 'Fender': 7500, 'Light': 4500, 'Windshield': 11000}})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Cloning into GitHub***"
      ],
      "metadata": {
        "id": "QsfEoOuY6zM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Ananya29J/CodeHer_25-InSpec-AI.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZWo8rZNUgIV",
        "outputId": "1e65927f-7663-4cb3-fe7a-e3cd4fc9f421"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CodeHer_25-InSpec-AI'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/My\\ Drive/Vehicle_Defect_Detection/models/vehicle_damage_model.h5 /content/CodeHer_25-InSpec-AI/\n"
      ],
      "metadata": {
        "id": "9w8JvOXIU9Le"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}